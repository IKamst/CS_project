{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT.ipynb","provenance":[],"mount_file_id":"1dW342ah_X_M_9tUEbxCTSr03edAg0wAW","authorship_tag":"ABX9TyOOCewxnB1RG8wPNBymKFTE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yOov23Q6Qfku","executionInfo":{"status":"ok","timestamp":1643281426087,"user_tz":-60,"elapsed":46358,"user":{"displayName":"Rik Zijlema","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16715734862350772008"}},"outputId":"6428dcf7-763a-4edb-ad3e-650686060aa5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch_pretrained_bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[K     |████████████████████████████████| 123 kB 4.3 MB/s \n","\u001b[?25hCollecting boto3\n","  Downloading boto3-1.20.44-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 35.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.19.5)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.10.0+cu111)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.62.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.10.0.2)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 8.1 MB/s \n","\u001b[?25hCollecting botocore<1.24.0,>=1.23.44\n","  Downloading botocore-1.23.44-py3-none-any.whl (8.5 MB)\n","\u001b[K     |████████████████████████████████| 8.5 MB 44.5 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.44->boto3->pytorch_pretrained_bert) (2.8.2)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 45.2 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.44->boto3->pytorch_pretrained_bert) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 46.8 MB/s \n","\u001b[?25hInstalling collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.20.44 botocore-1.23.44 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.5.0 urllib3-1.25.11\n"]}],"source":["!pip install pytorch_pretrained_bert\n","import os\n","from tqdm import tqdm_notebook as tqdm\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils import data\n","import torch.optim as optim\n","from pytorch_pretrained_bert import BertTokenizer\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"]},{"cell_type":"code","source":["from google.colab import drive \n","drive.mount('/content/drive')\n","%cd /content/drive/My Drive/CS_project/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PhNniv0ATMMd","executionInfo":{"status":"ok","timestamp":1643281434974,"user_tz":-60,"elapsed":8891,"user":{"displayName":"Rik Zijlema","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16715734862350772008"}},"outputId":"b22ef8e3-8839-4fbc-f1b6-2b03f1ba854b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/CS_project\n"]}]},{"cell_type":"code","source":["from read_sentences import read_file\n","\n","filenames = ['gold_data/eval.conll', 'gold_data/test.conll']\n","with open('gold_data/testeval.conll', 'w') as outfile:\n","    for fname in filenames:\n","        with open(fname) as infile:\n","            for line in infile:\n","                outfile.write(line)\n","\n","train_sent, train_tagged_sent = read_file(\"gold_data/train.conll\")\n","eval_sent, eval_tagged_sent = read_file(\"gold_data/testeval.conll\")\n","\n","tags = list(set(word_tag[1] for sent in train_tagged_sent for word_tag in sent))\n","\",\".join(tags)\n","tags = [\"<pad>\"] + tags\n","\n","tag2idx = {tag:idx for idx, tag in enumerate(tags)}\n","idx2tag = {idx:tag for idx, tag in enumerate(tags)}"],"metadata":{"id":"Gp1einV-RiZs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"gugpr6kMj05O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"],"metadata":{"id":"qtdUvQ8Ij17A","executionInfo":{"status":"ok","timestamp":1643281441650,"user_tz":-60,"elapsed":2258,"user":{"displayName":"Rik Zijlema","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16715734862350772008"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb83132e-171c-4ea9-a0cc-929638fcb52f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 213450/213450 [00:00<00:00, 292623.18B/s]\n"]}]},{"cell_type":"code","source":["class SMTDataset(data.Dataset):\n","    def __init__(self, tagged_sents):\n","        sents, tags_li = [], []\n","        for sent in tagged_sents:\n","            words = [word_tag[0] for word_tag in sent]\n","            tags = [word_tag[1] for word_tag in sent]\n","            sents.append([\"[CLS]\"] + words + [\"[SEP]\"])\n","            tags_li.append([\"<pad>\"] + tags + [\"<pad>\"])\n","        self.sents, self.tags_li = sents, tags_li\n","\n","    def __len__(self):\n","        return len(self.sents)\n","\n","    def __getitem__(self, idx):\n","        words, tags = self.sents[idx], self.tags_li[idx]\n","\n","        x, y = [], []\n","        is_heads = []\n","        for w, t in zip(words, tags):\n","            tokens = tokenizer.tokenize(w) if w not in (\"[CLS]\", \"[SEP]\") else [w]\n","            xx = tokenizer.convert_tokens_to_ids(tokens)\n","            is_head = [1] + [0]*(len(tokens) - 1)\n","\n","            t = [t] + [\"<pad>\"] * (len(tokens) - 1)\n","            yy = [tag2idx[each] for each in t]\n","\n","            x.extend(xx)\n","            is_heads.extend(is_head)\n","            y.extend(yy)\n","\n","        assert len(x)==len(y)==len(is_heads), \"len(x)={}, len(y)={}, len(is_heads)={}\".format(len(x), len(y), len(is_heads))\n","\n","        seqlen = len(y)\n","\n","        words = \" \".join(words)\n","        tags = \" \".join(tags)\n","        return words, x, is_heads, tags, y, seqlen"],"metadata":{"id":"3TnrYIf8j6JA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pad(batch):\n","    f = lambda x: [sample[x] for sample in batch]\n","    words = f(0)\n","    is_heads = f(2)\n","    tags = f(3)\n","    seqlens = f(-1)\n","    maxlen = np.array(seqlens).max()\n","\n","    f = lambda x, seqlen: [sample[x] + [0] * (seqlen - len(sample[x])) for sample in batch]\n","    x = f(1, maxlen)\n","    y = f(-2, maxlen)\n","\n","\n","    f = torch.LongTensor\n","\n","    return words, f(x), is_heads, tags, f(y), seqlens"],"metadata":{"id":"z4qHj69Vj-KJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pytorch_pretrained_bert import BertModel"],"metadata":{"id":"Y0xC1MULkApX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Net(nn.Module):\n","    def __init__(self, vocab_size=None):\n","        super().__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-cased')\n","\n","        self.fc = nn.Linear(768, vocab_size)\n","        self.device = device\n","\n","    def forward(self, x, y):\n","\n","        x = x.to(device)\n","        y = y.to(device)\n","        \n","        if self.training:\n","            self.bert.train()\n","            encoded_layers, _ = self.bert(x)\n","            enc = encoded_layers[-1]\n","        else:\n","            self.bert.eval()\n","            with torch.no_grad():\n","                encoded_layers, _ = self.bert(x)\n","                enc = encoded_layers[-1]\n","        \n","        logits = self.fc(enc)\n","        y_hat = logits.argmax(-1)\n","        return logits, y, y_hat"],"metadata":{"id":"04iTbRM_kEKx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, iterator, optimizer, criterion):\n","    model.train()\n","    for i, batch in enumerate(iterator):\n","        words, x, is_heads, tags, y, seqlens = batch\n","        _y = y\n","        optimizer.zero_grad()\n","        logits, y, _ = model(x, y)\n","\n","        logits = logits.view(-1, logits.shape[-1])\n","        y = y.view(-1)\n","\n","        loss = criterion(logits, y)\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        if i%10==0:\n","            print(\"step: {}, loss: {}\".format(i, loss.item()))"],"metadata":{"id":"xEgZi5aDkG7e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def eval(model, iterator):\n","    model.eval()\n","\n","    Words, Is_heads, Tags, Y, Y_hat = [], [], [], [], []\n","    with torch.no_grad():\n","        for i, batch in enumerate(iterator):\n","            words, x, is_heads, tags, y, seqlens = batch\n","\n","            _, _, y_hat = model(x, y)\n","\n","            Words.extend(words)\n","            Is_heads.extend(is_heads)\n","            Tags.extend(tags)\n","            Y.extend(y.numpy().tolist())\n","            Y_hat.extend(y_hat.cpu().numpy().tolist())\n","\n","    # get results and save\n","    with open(\"result.txt\", 'w') as fout:\n","        for words, is_heads, tags, y_hat in zip(Words, Is_heads, Tags, Y_hat):\n","            y_hat = [hat for head, hat in zip(is_heads, y_hat) if head == 1]\n","            preds = [idx2tag[hat] for hat in y_hat]\n","            assert len(preds)==len(words.split())==len(tags.split())\n","            for w, t, p in zip(words.split()[1:-1], tags.split()[1:-1], preds[1:-1]):\n","                fout.write(\"{} {} {}\\n\".format(w, t, p))\n","            fout.write(\"\\n\")\n","            \n","    # calculate metrics\n","    y_true =  np.array([tag2idx[line.split()[1]] for line in open('result.txt', 'r').read().splitlines() if len(line) > 0])\n","    y_pred =  np.array([tag2idx[line.split()[2]] for line in open('result.txt', 'r').read().splitlines() if len(line) > 0])\n","    \n","    print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n","    print(\"Precision: \", precision_score(y_true, y_pred, average=\"macro\"))\n","    print(\"Recall: \", recall_score(y_true, y_pred, average=\"macro\"))\n","    print(\"F-score: \", f1_score(y_true, y_pred, average=\"macro\"))"],"metadata":{"id":"73ssnRQckLbz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Net(vocab_size=len(tag2idx))\n","model.to(device)\n","model = nn.DataParallel(model)"],"metadata":{"id":"IXTJjT9VkOYr","executionInfo":{"status":"ok","timestamp":1643281492431,"user_tz":-60,"elapsed":50293,"user":{"displayName":"Rik Zijlema","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16715734862350772008"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3e18aeda-3f58-45f7-9ff7-1668680ac49e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 404400730/404400730 [00:30<00:00, 13172885.31B/s]\n"]}]},{"cell_type":"code","source":["train_dataset = SMTDataset(train_tagged_sent)\n","eval_dataset = SMTDataset(eval_tagged_sent)\n","\n","train_iter = data.DataLoader(dataset=train_dataset,\n","                             batch_size=16,\n","                             shuffle=True,\n","                             num_workers=1,\n","                             collate_fn=pad)\n","test_iter = data.DataLoader(dataset=eval_dataset,\n","                             batch_size=16,\n","                             shuffle=False,\n","                             num_workers=1,\n","                             collate_fn=pad)\n","\n","optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=0)"],"metadata":{"id":"2jluCSS-kXc6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train(model, train_iter, optimizer, criterion)\n","eval(model, test_iter)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"49Mjtj7pkeIA","executionInfo":{"status":"error","timestamp":1643281598030,"user_tz":-60,"elapsed":105609,"user":{"displayName":"Rik Zijlema","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16715734862350772008"}},"outputId":"324c7261-7897-4ed0-8a4b-1d080486e6b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["step: 0, loss: 4.287162780761719\n","step: 10, loss: 2.1621651649475098\n","step: 20, loss: 0.8451504111289978\n","step: 30, loss: 0.8115382194519043\n","step: 40, loss: 0.6449341177940369\n","step: 50, loss: 0.31196263432502747\n","step: 60, loss: 0.38537073135375977\n","step: 70, loss: 0.29861655831336975\n","step: 80, loss: 0.26663848757743835\n","step: 90, loss: 0.259267657995224\n","step: 100, loss: 0.2070050835609436\n","step: 110, loss: 0.12061232328414917\n","step: 120, loss: 0.08054866641759872\n","step: 130, loss: 0.05581691861152649\n","step: 140, loss: 0.0645441934466362\n","step: 150, loss: 0.18107633292675018\n","step: 160, loss: 0.1619790643453598\n","step: 170, loss: 0.19197355210781097\n","step: 180, loss: 0.09833307564258575\n","step: 190, loss: 0.28944987058639526\n","step: 200, loss: 0.09460791945457458\n","step: 210, loss: 0.06915973871946335\n","step: 220, loss: 0.055473748594522476\n","step: 230, loss: 0.2306976169347763\n","step: 240, loss: 0.10406902432441711\n","step: 250, loss: 0.17786699533462524\n","step: 260, loss: 0.11540894210338593\n","step: 270, loss: 0.05959394574165344\n","step: 280, loss: 0.1310885101556778\n","step: 290, loss: 0.07985877245664597\n","step: 300, loss: 0.2368316352367401\n","step: 310, loss: 0.04137111455202103\n","step: 320, loss: 0.018250979483127594\n","step: 330, loss: 0.08233056962490082\n","step: 340, loss: 0.08553265035152435\n","step: 350, loss: 0.1630675047636032\n","step: 360, loss: 0.029017992317676544\n","step: 370, loss: 0.2630282938480377\n","step: 380, loss: 0.08898668736219406\n","step: 390, loss: 0.228107750415802\n","step: 400, loss: 0.1219012513756752\n","step: 410, loss: 0.20752647519111633\n","step: 420, loss: 0.03771780803799629\n","step: 430, loss: 0.04025445505976677\n","step: 440, loss: 0.05727333202958107\n","step: 450, loss: 0.03674961254000664\n","step: 460, loss: 0.03239242732524872\n","step: 470, loss: 0.08610755205154419\n","step: 480, loss: 0.11440432816743851\n","Accuracy:  0.9779746229351209\n","Precision:  0.8563893316370862\n","Recall:  0.8249002529330933\n","F-score:  0.8351457390920635\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-ea503cd9d832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-efb7bb855970>\u001b[0m in \u001b[0;36meval\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F-score: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2119\u001b[0m     \u001b[0;31m# labelled micro average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2120\u001b[0m     micro_is_accuracy = (y_type == \"multiclass\" or y_type == \"binary\") and (\n\u001b[0;32m-> 2121\u001b[0;31m         \u001b[0;32mnot\u001b[0m \u001b[0mlabels_given\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2122\u001b[0m     )\n\u001b[1;32m   2123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d array"]}]},{"cell_type":"code","source":["open('result.txt', 'r').read().splitlines()[:250]"],"metadata":{"id":"Knk74t0AlSxq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import Counter, OrderedDict\n","import matplotlib.pylab as plt\n","\n","file = open(\"result.txt\", \"r\")\n","\n","words, correct_class, wrong_class = [], [], []\n","\n","for line in file:\n","  line = line.split()\n","  if len(line) > 1:\n","    if line[1] != line[2]:\n","      words.append(line[0])\n","      correct_class.append(line[1])\n","      wrong_class.append(line[2])      \n","file.close()\n","\n","correct_counts = Counter(correct_class)\n","wrong_counts = Counter(wrong_class)\n","\n","correct_counts = dict(sorted(correct_counts.items(), key=lambda item: item[1], reverse=True))\n","\n","x = [] # keys\n","y = [] # values\n","for key, value in correct_counts.items():\n","\tif value >= 4:\n","\t\tx.append(key)\n","\t\ty.append(value)\n","plt.bar(x,y, color = 'green')\n","\n","for i in range(len(x)):\n","    plt.text(i, y[i]//2, y[i], ha = 'center', fontsize = 8, fontweight='bold')\n","\n","\n","plt.title('Occurences of the Incorrectly Classified Semantic Tags by BERT', fontsize = 14, fontweight='bold', fontfamily='serif')\n","plt.xlabel('Semantic tag', fontweight='bold', fontfamily='serif', fontsize = 12)\n","plt.ylabel('Number of occurences', fontweight='bold', fontfamily='serif', fontsize = 12)\n","#plt.savefig(\"incorrectly_classified_baseline.png\")\n","plt.show()\n"],"metadata":{"id":"qTm5cKfd540h"},"execution_count":null,"outputs":[]}]}